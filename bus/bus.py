# -*- coding: utf-8 -*-
"""bus.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jHC0A3diHQRA4ln2fUgT_FfAh8DBQTyc
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

import lightgbm as lgb
import folium

train = pd.read_csv('/content/drive/MyDrive/bus/train.csv')
test = pd.read_csv('/content/drive/MyDrive/bus/test.csv')
submission = pd.read_csv('/content/drive/MyDrive/bus/submission_제출양식.csv')

train.head()

test.head()

submission.head()

train.shape

"""id 기준 0~210456까지 총 210457개의 row와 14개의 칼럼이 존재한다."""

train.info()

"""- id : 해당 데이터의 고유한 ID
- date : 버스 운행 날짜
- route_id : 버스 노선 ID
- vh_id : 버스 ID
- route_nm : 버스 노선 실제 번호
- now_latitude : 현재 정류소의 위도
- now_longtitude : 현재 정류소의 경도
- now_station : 현재 정류소 이름
- now_arrive_time : 현재 정류장에 도착한 시간
- distance : 현재 정류장에서 다음 정류장까지 실제 이동한 거리
- next_station : 다음 정류소 이름
- next_latitude : 다음 정류서의 위도
- next_longtitude : 다음 정류소의 경도
- next_arrive_time : target, 다음 정류장에 도착할때 까지 걸린 시간(초)


"""

train.isnull().sum()

# 결측치는 존재하지 않는다.

test.isnull().sum()

train.route_id.unique()

test.route_id.unique()

train.route_id.nunique()

test.route_id.nunique()

"""총 21 개의 루트가 존재한다.


"""

train.vh_id.unique()

test.vh_id.nunique()

train.vh_id.nunique()

"""train : 총 104대의 버스가 존재한다.<br>
test : 총 100대의 버스가 존재한다.


"""

train[['route_id','vh_id']]
# 중복 되는게 많다.

train[['route_id','vh_id']].drop_duplicates().groupby('route_id').count()
# 많게는 15개, 적게는 1개 버스가 운행한다.

# 노선별로 next_arrive_time 을 확인한다
train[['route_id','next_arrive_time']].groupby('route_id').mean()

# 노선에 따라 평균이 꽤 차이가 나는 것을 확인한다.

map_data = train[['route_id','now_latitude','now_longitude','now_station']]

# 405136521 = 제일 시간이 오래 걸린 노선.
map_bus_route_max = map_data[map_data['route_id'] == 405136521].drop_duplicates("now_station")
# 405320122 = 제일 시간이 짧게 걸린 노선
map_bus_route_min = map_data[map_data['route_id'] == 405320122].drop_duplicates("now_station")




# 제일 시간이 짧게 걸린 노선을 보면

map_osm_min = folium.Map(location=[33.4134, 126.5190], zoom_start = 10.5)

for item in map_bus_route_min.index:
    lat = map_bus_route_min.loc[item,'now_latitude']
    long = map_bus_route_min.loc[item,'now_longitude']
    
    folium.Marker([lat,long], popup = map_bus_route_min.loc[item,'now_station'],
                      icon = folium.Icon(color = 'red', icon = 'info-sign')
                      ).add_to(map_osm_min)

map_osm_min.save('index.html')

map_osm_min



# 제일 시간이 길게 걸린 노선을 보면

map_osm_max = folium.Map(location=[33.4134, 126.5190], zoom_start = 10.5)



for item in map_bus_route_max.index:
    lat = map_bus_route_max.loc[item,'now_latitude']
    long = map_bus_route_max.loc[item,'now_longitude']
    
    folium.Marker([lat,long], popup = map_bus_route_max.loc[item,'now_station'],
                      icon = folium.Icon(color = 'red', icon = 'info-sign')
                      ).add_to(map_osm_max)

map_osm_max.save('index.html')

map_osm_max



train.route_nm.unique()

train.route_nm.nunique()

"""route_nm이 route_id 보다 더 보기 편한 것 같다."""

train.now_station.nunique()

test.now_station.nunique()

"""train : 348개의 정류소가 존재한다.
test : 349개의 정류소가 존재한다.
"""

# 왜 차이가 날까?
# 제주 한라 대학교가 없다.

train[train['now_station']=='제주한라대학교(종점)']

train.now_station.unique()

train.now_station.value_counts()

test.now_station.value_counts()

# 기준이어서 시 단위로 끊어진 것 같다.
train.now_arrive_time.value_counts()

plt.figure(figsize=(25,4))
sns.countplot(data = train, x= "now_arrive_time")

plt.figure(figsize=(25,4))
sns.countplot(data=test,x="now_arrive_time")

# 00시가 test data에서는 존재하지 않는다.

plt.figure(figsize=(25,4))
sns.countplot(data = train,x = "distance")


# 거리가 뚜렷한 경향이 보이지는 않지만 distance가 큰 정류장은 작아보인다.

train.next_station.value_counts()

test.next_station.value_counts()

"""next station은 test data에서 또 하나가 적다.
아마 전경대 입구가 아닐까......?
"""

test[test['next_station']=='전경대 입구']

# 전경대 입구가 없다.

train.next_arrive_time.value_counts()

plt.figure(figsize=(25,4))
sns.countplot(data=train, x="next_arrive_time")

train = train.sort_values(by='next_arrive_time')

train['next_arrive_time'].describe()

"""이상치로 보이는 값들은 좀 없앨 필요가 있어 보인다.
이상치를 어떻게 판별할 수 있을까?

data cleansing & pre-processing
"""

# now_arrive_time 에 문자를 빼서 바로 수치형으로 바꿔줘야 한다.
train.now_arrive_time

train['now_arrive_time'] = train['now_arrive_time'].str.slice(stop=-1).astype('int')

train.info()

test['now_arrive_time'] = test['now_arrive_time'].str.slice(stop=-1).astype('int')

test.info()

"""Modeling"""

# features에 이것만 넣어서 해보자.

features = ['now_latitude','now_longitude','now_arrive_time','distance']
target = ['next_arrive_time']

X_train,X_test,y_train = train[features],test[features],train[target]

from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression

# dictionary 만들어서 모델을 모아두기.
model_dict = {
    'linear':LinearRegression(),
    'rf' : RandomForestRegressor(random_state=0, n_jobs=-1),
    'lgbm':lgb.LGBMRegressor(random_state=0)
}

model_dict

model_dict.keys()

model_dict['linear']

model_result = {}

for key in model_dict.keys():
  print('##### 훈련중 #####')
  model_dict[key].fit(X_train,y_train)
  print('##### 예측중 #####')
  model_result[key] = model_dict[key].predict(X_test)

lr_submit=submission.copy()
rf_submit=submission.copy()
lgbm_submit = submission.copy()

lr_submit['next_arrive_time']= model_result['linear']
rf_submit['next_arrive_time']= model_result['rf']
lgbm_submit['next_arrive_time']= model_result['lgbm']

lr_submit.to_csv('lr_submit.csv',index=False)
rf_submit.to_csv('rf_submit.csv',index=False)
lgbm_submit.to_csv('lgbm_submit.csv',index=False)

